{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75c9663-b6f6-4058-9484-09bf9a561d86",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PyTorch parameter\n",
    "Reference\n",
    "- [Constructing parameter groups in pytorch](https://stackoverflow.com/questions/69774137/constructing-parameter-groups-in-pytorch)\n",
    "- [PyTorch: What's the difference between state_dict and parameters()?](https://stackoverflow.com/questions/54746829/pytorch-whats-the-difference-between-state-dict-and-parameters)\n",
    "- [What pytorch means by buffers?](https://discuss.pytorch.org/t/what-pytorch-means-by-buffers/120266)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e5c6b2-0c31-4420-8897-4a81bd1f9d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=16, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(16, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "opt = SGD(model.parameters(), lr=0.01)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8727008a-99a9-40ba-8ffc-f5c88919b086",
   "metadata": {},
   "source": [
    "## Get parameters\n",
    "- model.named_parameters() returns a generator\n",
    "- each call to the generator produced a tuple `(paramter_name, torch.nn.parameter.Parameter)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7533be-fa61-4eb8-9029-cfb7e025b54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('fc1.weight',\n",
       " Parameter containing:\n",
       " tensor([[-0.0052,  0.1259,  0.1436,  ...,  0.1291, -0.2167,  0.1890],\n",
       "         [-0.1982,  0.2269,  0.1691,  ...,  0.0108,  0.2383, -0.0038],\n",
       "         [ 0.0908, -0.0608,  0.0193,  ...,  0.1351,  0.2323,  0.1127],\n",
       "         ...,\n",
       "         [ 0.2033, -0.1474, -0.1043,  ..., -0.0095,  0.0411, -0.2085],\n",
       "         [-0.1480,  0.1185,  0.2237,  ...,  0.1508,  0.0838, -0.0118],\n",
       "         [-0.2084,  0.1216, -0.1767,  ..., -0.2042,  0.1350,  0.1368]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(model.named_parameters()))\n",
    "next(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b24cf66-9119-4fbe-ba84-d0e5e626d8d9",
   "metadata": {},
   "source": [
    "## Fix parameters\n",
    "- To fix a `torch.nn.parameter.Parameter` (say `model.fc1.weight`), set `.requires_grad = False`\n",
    "- Calling `.backward()` will no accumulate gradient on `model.fc1.weight`. Therefore, `optimizer.step` will no change `model.fc1.weight`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b82d9956-3df7-4608-b94f-eae18b7ffd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_weight_copy = deepcopy(model.fc1.weight.detach())\n",
    "fc2_weight_copy = deepcopy(model.fc2.weight.detach())\n",
    "\n",
    "model.fc1.weight.requires_grad = False\n",
    "model.fc1.bias.requires_grad = False\n",
    "\n",
    "opt.zero_grad() \n",
    "\n",
    "x = torch.normal(0, 1, [16])\n",
    "y = model(x)\n",
    "\n",
    "loss = F.mse_loss(y , torch.tensor([5.0]))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3005d3d9-2cd5-476e-b195-e0a93ca27d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23.1273, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "458fddbd-2da7-4228-bcad-e21b66eebf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2686],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight.grad)\n",
    "print(model.fc2.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2ede9c2-fd33-4276-8558-a419f5b07501",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "983e5b0c-be31-4a3e-be33-7e4674ce8405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(0.1701, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print((model.fc1.weight - fc1_weight_copy).sum())\n",
    "print((model.fc2.weight - fc2_weight_copy).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1035f49-486d-4615-8ff1-903acd0eb25b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters vs buffer vs state_dict\n",
    "- parameters: tensors that require gradients\n",
    "- buffer: tensors that do not require gradients (e.g., mean and std in batchnorm layers)\n",
    "- state_dict: contains elements from both parameters and buffer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5254298-4194-46f4-bbde-d992fdf11d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=16, out_features=64, bias=True)\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(16, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "opt = SGD(model.parameters(), lr=0.01)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7293c0aa-8014-47f2-b5bd-df5d82f4cc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bn1.running_mean',\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       " ('bn1.running_var',\n",
       "  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       " ('bn1.num_batches_tracked', tensor(0))]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_buffers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "efba45a3-65bb-4c8f-ab03-265e10915a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[-1.3200e-01, -5.9882e-02, -9.9831e-02,  ..., -1.5544e-01,\n",
      "         -1.9045e-01,  5.3080e-02],\n",
      "        [-5.7073e-02, -9.8052e-02, -1.7600e-01,  ..., -1.1753e-02,\n",
      "          1.1653e-01, -2.3358e-01],\n",
      "        [ 7.1093e-02,  2.1064e-01, -1.9982e-01,  ..., -1.4521e-01,\n",
      "         -1.4367e-01, -5.0642e-02],\n",
      "        ...,\n",
      "        [ 2.4479e-01,  1.0007e-01, -8.1331e-05,  ..., -1.4318e-01,\n",
      "         -2.2091e-01,  6.5968e-02],\n",
      "        [ 9.6643e-02,  1.4006e-01, -2.4466e-02,  ...,  1.0410e-01,\n",
      "          1.3157e-01,  2.1909e-01],\n",
      "        [ 2.3638e-01,  1.4358e-01, -1.5742e-01,  ...,  2.1863e-01,\n",
      "          2.7791e-02, -1.6912e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict()['bn1.weight'])\n",
    "print(model.state_dict()['fc1.weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff9472-6939-4c24-bbaf-4ca79ab11354",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameter Group\n",
    "- For a complex network, we can declare a parameter group and define update rules to the parameter group.\n",
    "- Procedure: define a class attribute, say `self.params` as a `nn.ModuleDict` and group parameters using `nn.ModuleLists`\n",
    "- Can fix parameter group or set different learning rate\n",
    "    - For SGD, the input params could iterable of parameters to optimize or dicts defining parameter groups\n",
    "    - In the example below, `[fc1, fc2]` have different learning rate and momentum than `fc3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76fd82ed-9a88-44ed-953f-62e85e5df33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(16, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        \n",
    "        self.params = nn.ModuleDict({\n",
    "            'base': nn.ModuleList([self.fc1, self.fc2]),\n",
    "            'regressor': nn.ModuleList([self.fc3])})\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a0fac3b-246f-4c0b-a490-fbf84b74d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(\n",
    "    [\n",
    "        {'params': model.params.base.parameters()},\n",
    "        {'params': model.params.regressor.parameters(), 'lr': 1e-3, 'momentum': 0}\n",
    "    ], \n",
    "    lr=1e-2, \n",
    "    momentum=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61aa2eec-9cb3-4441-8063-a18202761f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0.9\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    dampening: 0\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f1f97-0c8d-43ef-9e6d-059a07091e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
